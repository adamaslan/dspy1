{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: 'your_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# pip install dspy-ai transformers pandas\n",
    "\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class HuggingFaceLanguageModel(dspy.LM):\n",
    "    \"\"\"\n",
    "    Custom Language Model wrapper for Hugging Face transformers\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='facebook/opt-350m'):\n",
    "        self.generator = pipeline('text-generation', model=model_name)\n",
    "    \n",
    "    def __call__(self, prompt: str, **kwargs):\n",
    "        # Convert Hugging Face pipeline output to DSPy format\n",
    "        response = self.generator(prompt, max_length=150, **kwargs)[0]['generated_text']\n",
    "        return dspy.Prediction(text=response)\n",
    "\n",
    "class DataProcessor(dspy.Module):\n",
    "    \"\"\"\n",
    "    DSPy Module for processing CSV data and generating insights\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str, column_to_search: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load CSV data\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.column_to_search = column_to_search\n",
    "        \n",
    "        # Configure DSPy with Hugging Face Language Model\n",
    "        self.language_model = HuggingFaceLanguageModel()\n",
    "        dspy.settings.configure(lm=self.language_model)\n",
    "    \n",
    "    def search_data(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Search CSV data and generate insights\n",
    "        \"\"\"\n",
    "        # Filter dataframe based on query\n",
    "        results = self.df[self.df[self.column_to_search].str.contains(query, case=False, na=False)]\n",
    "        \n",
    "        # Generate summary using language model\n",
    "        summary_prompt = f\"Summarize these {len(results)} results about '{query}': {results.to_string()}\"\n",
    "        summary = self.language_model(summary_prompt).text\n",
    "        \n",
    "        return {\n",
    "            'query_results': results,\n",
    "            'result_count': len(results),\n",
    "            'summary': summary\n",
    "        }\n",
    "    \n",
    "    def advanced_analysis(self, query: str, additional_columns: List[str] = None):\n",
    "        \"\"\"\n",
    "        Perform more advanced analysis with multiple columns\n",
    "        \"\"\"\n",
    "        results = self.search_data(query)\n",
    "        \n",
    "        if additional_columns:\n",
    "            # Aggregate additional columns if specified\n",
    "            aggregations = {col: ['mean', 'count'] for col in additional_columns \n",
    "                            if self.df[col].dtype in ['int64', 'float64']}\n",
    "            \n",
    "            additional_stats = results['query_results'].agg(aggregations)\n",
    "            results['additional_stats'] = additional_stats\n",
    "        \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    try:\n",
    "        # Initialize processor with your CSV and specify search column\n",
    "        processor = DataProcessor(\n",
    "            csv_path='your_data.csv',  # Replace with your CSV path\n",
    "            column_to_search='description'  # Replace with your column name\n",
    "        )\n",
    "        \n",
    "        # Simple search\n",
    "        simple_result = processor.search_data('example query')\n",
    "        print(\"Simple Search Results:\")\n",
    "        print(simple_result['query_results'])\n",
    "        print(\"\\nSummary:\", simple_result['summary'])\n",
    "        \n",
    "        # Advanced analysis with multiple columns\n",
    "        advanced_result = processor.advanced_analysis(\n",
    "            query='example query', \n",
    "            additional_columns=['price', 'rating']\n",
    "        )\n",
    "        print(\"\\nAdvanced Analysis:\")\n",
    "        print(advanced_result['additional_stats'])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input to embed_fn is empty after preprocessing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 69\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m passages \u001b[38;5;241m=\u001b[39m df[column_name]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Create custom retriever\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mCustomHFRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpassages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[1;32m     72\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInnovative technology ideas\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36mCustomHFRetriever.__init__\u001b[0;34m(self, passages, model_name, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_passages(texts)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create DSPy's Embeddings index\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nunu24/lib/python3.12/site-packages/dspy/retrievers/embeddings.py:26\u001b[0m, in \u001b[0;36mEmbeddings.__init__\u001b[0;34m(self, corpus, embedder, k, callbacks, cache, brute_force_threshold, normalize)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus \u001b[38;5;241m=\u001b[39m corpus\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;241m=\u001b[39m normalize\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_faiss() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(corpus) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m brute_force_threshold \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mCustomHFRetriever.__init__.<locals>.embed_fn\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     28\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(t)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m texts:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to embed_fn is empty after preprocessing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_passages(texts)\n",
      "\u001b[0;31mValueError\u001b[0m: The input to embed_fn is empty after preprocessing."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from typing import List, Dict, Any\n",
    "import torch\n",
    "import numpy as np\n",
    "from dspy.retrievers import Embeddings  # Assuming Embeddings is imported from dspy.\n",
    "\n",
    "class CustomHFRetriever:\n",
    "    def __init__(self, passages, model_name=\"sentence-transformers/all-mpnet-base-v2\", batch_size=32):\n",
    "        # Initialize tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Check if MPS (Metal Performance Shaders) is available for Apple Silicon; otherwise, use CPU\n",
    "        self.device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Clean and encode passages\n",
    "        self.passages = [str(p).strip() for p in passages if isinstance(p, str) and p.strip()]\n",
    "        if not self.passages:\n",
    "            raise ValueError(\"The passages list is empty after preprocessing.\")\n",
    "        \n",
    "        self.embeddings = self._encode_passages(self.passages)\n",
    "        \n",
    "        # Define an embedding function\n",
    "        def embed_fn(texts):\n",
    "            texts = [str(t).strip() for t in texts if isinstance(t, str) and t.strip()]\n",
    "            if not texts:\n",
    "                raise ValueError(\"The input to embed_fn is empty after preprocessing.\")\n",
    "            return self._encode_passages(texts)\n",
    "        \n",
    "        # Create DSPy's Embeddings index\n",
    "        self.index = Embeddings(self.embeddings, embedder=embed_fn)\n",
    "    \n",
    "    def _encode_passages(self, passages):\n",
    "        \"\"\"Encodes passages using the model in batches.\"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(passages), self.batch_size):\n",
    "            batch = passages[i:i + self.batch_size]\n",
    "            if not batch:  # Skip empty batches\n",
    "                continue\n",
    "            inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                # Use mean pooling over token embeddings\n",
    "                embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "        if not embeddings:\n",
    "            raise ValueError(\"No embeddings were generated. Check the input passages and preprocessing.\")\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[str]:\n",
    "        \"\"\"Searches for the top_k most similar passages to the query.\"\"\"\n",
    "        query_embedding = self._encode_passages([query])[0]\n",
    "        return self.index.most_similar(query_embedding, top_k=top_k)\n",
    "\n",
    "def main():\n",
    "    # Load data from the CSV file\n",
    "    df = pd.read_csv(\"./151_ideas_updated.csv\", usecols=[0, 1, 2, 3, 4, 5])\n",
    "    \n",
    "    # Ensure the correct column is used for passages\n",
    "    df.columns = df.columns.str.strip()  # Remove any extra spaces in column names\n",
    "    column_name = \"Ideas\"  # Replace with the actual column name if different\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in CSV.\")\n",
    "    passages = df[column_name].dropna().tolist()\n",
    "    \n",
    "    # Create custom retriever\n",
    "    retriever = CustomHFRetriever(passages)\n",
    "    \n",
    "    # Example query\n",
    "    query = \"Innovative technology ideas\"\n",
    "    retrieved_passages = retriever.search(query)\n",
    "    \n",
    "    # Print retrieved passages\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nRetrieved Passages:\")\n",
    "    for idx, passage in enumerate(retrieved_passages, 1):\n",
    "        print(f\"{idx}. {passage}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
