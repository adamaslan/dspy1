{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Knowledge graph loaded successfully.\n",
      "Query: How can mindfulness improve well-being and inner beauty?\n",
      "Debug: Searching for relevant nodes and edges for query: How can mindfulness improve well-being and inner beauty?\n",
      "Debug: Found relevant node: mindfulness\n",
      "Debug: Found relevant edge: ('mindfulness', 'meditation', {'relationship': 'develops'})\n",
      "An error occurred: unhashable type: 'dict'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize GPT-2 Model\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize the tokenizer and GPT-2 model.\"\"\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")  # Set padding_side to 'left'\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\").half()  # Load GPT-2 in half-precision\n",
    "    model.to(device)  # Ensure itâ€™s on the correct device\n",
    "\n",
    "    # Set pad_token (GPT-2 doesn't have one by default, so we use eos_token as pad_token)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "# Create Knowledge Graph from CSV\n",
    "def create_knowledge_graph_from_csv(csv_path):\n",
    "    \"\"\"Create a knowledge graph from a CSV file.\"\"\"\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Read CSV file\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        idea = row['Ideas']\n",
    "        themes = [row['Theme a'], row['Theme-b'], row['Theme-c']]\n",
    "\n",
    "        # Add nodes for the idea and its themes\n",
    "        graph.add_node(idea)\n",
    "        for theme in themes:\n",
    "            if pd.notna(theme):\n",
    "                graph.add_node(theme)\n",
    "                graph.add_edge(idea, theme, relationship=\"relates_to\")\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Retrieve Knowledge from Graph\n",
    "def retrieve_from_graph(graph, query):\n",
    "    \"\"\"Retrieve relevant information from the knowledge graph based on the input query.\"\"\"\n",
    "    relevant_nodes = set()\n",
    "    relevant_edges = set()\n",
    "\n",
    "    print(f\"Debug: Searching for relevant nodes and edges for query: {query}\")\n",
    "    for node in graph.nodes:\n",
    "        if any(keyword.lower() in query.lower() for keyword in node.split()):\n",
    "            print(f\"Debug: Found relevant node: {node}\")\n",
    "            relevant_nodes.add(node)\n",
    "\n",
    "    for edge in graph.edges(data=True):\n",
    "        if edge[0] in relevant_nodes or edge[1] in relevant_nodes:\n",
    "            print(f\"Debug: Found relevant edge: {edge}\")\n",
    "            relevant_edges.add(edge)\n",
    "\n",
    "    return list(relevant_nodes), list(relevant_edges)\n",
    "\n",
    "# Generate Context-Aware Responses\n",
    "def generate_with_graph_knowledge(query, model, tokenizer, graph):\n",
    "    \"\"\"Generate a response based on a query and relevant knowledge from the graph.\"\"\"\n",
    "    relevant_nodes, relevant_edges = retrieve_from_graph(graph, query)\n",
    "\n",
    "    # If no knowledge is found, provide a fallback message\n",
    "    if not relevant_nodes and not relevant_edges:\n",
    "        context = f\"Query: {query}\\nRelevant Knowledge: No relevant knowledge found in the graph.\"\n",
    "    else:\n",
    "        context = f\"Query: {query}\\nRelevant Knowledge:\\n\"\n",
    "        for node in relevant_nodes:\n",
    "            context += f\" - Node: {node}\\n\"\n",
    "        for edge in relevant_edges:\n",
    "            context += f\" - Edge: {edge[0]} ({edge[2]['relationship']}) {edge[1]}\\n\"\n",
    "\n",
    "    # Use GPT-2 to generate a response\n",
    "    inputs = tokenizer(context, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=200, \n",
    "        num_return_sequences=1, \n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Save and Load Knowledge Graph\n",
    "def save_graph(graph, filepath=\"knowledge_graph.pkl\"):\n",
    "    \"\"\"Save the knowledge graph to a file.\"\"\"\n",
    "    import pickle\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(graph, f)\n",
    "\n",
    "def load_graph(filepath=\"knowledge_graph.pkl\"):\n",
    "    \"\"\"Load the knowledge graph from a file.\"\"\"\n",
    "    import pickle\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Main Processing Function\n",
    "def main():\n",
    "    \"\"\"Main processing loop.\"\"\"\n",
    "    # Filepath to save/load the graph\n",
    "    save_path = \"knowledge_graph.pkl\"\n",
    "    csv_path = \"151_ideas_updated.csv\"\n",
    "\n",
    "    # Load or create the knowledge graph\n",
    "    try:\n",
    "        graph = load_graph(save_path)\n",
    "        print(\"Knowledge graph loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        graph = create_knowledge_graph_from_csv(csv_path)\n",
    "        save_graph(graph, save_path)\n",
    "        print(\"Knowledge graph created and saved.\")\n",
    "\n",
    "    # Initialize the model\n",
    "    tokenizer, model = initialize_model()\n",
    "\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"How can mindfulness improve well-being and inner beauty?\",\n",
    "        \"What is the relationship between pragmatism and philosophy?\",\n",
    "        \"Explain the connection between meditation and personal growth.\",\n",
    "        \"How does Nietzsche's view on intention relate to modern life?\",\n",
    "        \"What role does beauty play in rational decision-making?\"\n",
    "    ]\n",
    "\n",
    "    # Generate responses for each query\n",
    "    for query in queries:\n",
    "        print(f\"Query: {query}\")\n",
    "        response = generate_with_graph_knowledge(query, model, tokenizer, graph)\n",
    "        print(f\"Response:\\n{response}\\n\")\n",
    "\n",
    "# Example Execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()  # Process the queries and generate responses\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Knowledge graph loaded successfully.\n",
      "Query: How can mindfulness improve well-being and inner beauty?\n",
      "Response:\n",
      "Query: How can mindfulness improve well-being and inner beauty?\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "The graph is based on a study of the effect of mindfulness on the quality of life of people. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the United Kingdom. The study was conducted in the United States and the\n",
      "\n",
      "Query: What is the relationship between pragmatism and philosophy?\n",
      "Response:\n",
      "Query: What is the relationship between pragmatism and philosophy?\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge:\n",
      "\n",
      "Query: Explain the connection between meditation and personal growth.\n",
      "Response:\n",
      "Query: Explain the connection between meditation and personal growth.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "The graph is based on a series of data from the National Health and Nutrition Examination Survey (NHANES) and the National Health and Nutrition Examination Survey (NHANES-NEP). The data are based on the National Health and Nutrition Examination Survey (NHANES-NEP) and the National Health and Nutrition Examination Survey (NHANES-NEP). The data are based on the National Health and Nutrition Examination Survey (NHANES-NEP) and the National Health and Nutrition Examination Survey (NHANES-NEP). The data are based on the National Health and Nutrition Examination Survey (NHANES-NEP) and the National Health and Nutrition Examination Survey (NHANES-NEP). The data are based on the National Health and Nutrition Examination Survey (NHANES-NEP) and the National Health and Nutrition Examination Survey (NHANES-NEP). The data are based on the National Health and Nutrition Examination Survey (NHANES-\n",
      "\n",
      "Query: How does Nietzsche's view on intention relate to modern life?\n",
      "Response:\n",
      "Query: How does Nietzsche's view on intention relate to modern life?\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "Relevant Knowledge:\n",
      "\n",
      "Query: What role does beauty play in rational decision-making?\n",
      "Response:\n",
      "Query: What role does beauty play in rational decision-making?\n",
      "Relevant Knowledge: No relevant knowledge found in the graph.\n",
      "The graph is a simple, but useful, way to visualize the relationship between beauty and decision-making. It shows the relationship between beauty and decision-making in a simple way.\n",
      "The graph is a simple, but useful, way to visualize the relationship between beauty and decision-making. It shows the relationship between beauty and decision-making in a simple way.\n",
      "The graph is a simple, but useful, way to visualize the relationship between beauty and decision-making. It shows the relationship between beauty and decision-making in a simple way.\n",
      "The graph is a simple, but useful, way to visualize the relationship between beauty and decision-making. It shows the relationship between beauty and decision-making in a simple way.\n",
      "The graph is a simple, but useful, way to visualize the relationship between beauty and decision-making. It shows the relationship between beauty and decision-making in a simple way.\n",
      "The graph is a simple, but useful, way to visualize the relationship\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pickle\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize GPT-2 Model\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize the tokenizer and GPT-2 model.\"\"\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.half()  # Use half-precision on GPU for efficiency\n",
    "    model.to(device)\n",
    "\n",
    "    # Set pad_token to eos_token for compatibility\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "# Create Knowledge Graph from CSV\n",
    "def create_knowledge_graph_from_csv(csv_path):\n",
    "    \"\"\"Create a knowledge graph from a CSV file.\"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"The file {csv_path} does not exist.\")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "    required_columns = ['Ideas', 'Theme a', 'Theme-b', 'Theme-c']\n",
    "    if not all(column in data.columns for column in required_columns):\n",
    "        raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    for _, row in data.iterrows():\n",
    "        idea = row['Ideas']\n",
    "        themes = [row['Theme a'], row['Theme-b'], row['Theme-c']]\n",
    "\n",
    "        graph.add_node(idea)\n",
    "        for theme in themes:\n",
    "            if pd.notna(theme):\n",
    "                graph.add_node(theme)\n",
    "                graph.add_edge(idea, theme, relationship=\"relates_to\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Retrieve Knowledge from Graph\n",
    "def retrieve_from_graph(graph, query):\n",
    "    \"\"\"Retrieve relevant information from the knowledge graph based on the input query.\"\"\"\n",
    "    relevant_nodes = set()\n",
    "    relevant_edges = set()\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        if query.lower() in node.lower():\n",
    "            relevant_nodes.add(node)\n",
    "\n",
    "    for edge in graph.edges(data=True):\n",
    "        if edge[0] in relevant_nodes or edge[1] in relevant_nodes:\n",
    "            relevant_edges.add(edge)\n",
    "\n",
    "    return list(relevant_nodes), list(relevant_edges)\n",
    "\n",
    "# Generate Context-Aware Responses\n",
    "def generate_with_graph_knowledge(query, model, tokenizer, graph):\n",
    "    \"\"\"Generate a response based on a query and relevant knowledge from the graph.\"\"\"\n",
    "    relevant_nodes, relevant_edges = retrieve_from_graph(graph, query)\n",
    "\n",
    "    if not relevant_nodes and not relevant_edges:\n",
    "        context = f\"Query: {query}\\nRelevant Knowledge: No relevant knowledge found in the graph.\"\n",
    "    else:\n",
    "        context = f\"Query: {query}\\nRelevant Knowledge:\\n\"\n",
    "        for node in relevant_nodes:\n",
    "            context += f\" - Node: {node}\\n\"\n",
    "        for edge in relevant_edges:\n",
    "            relationship = edge[2].get('relationship', 'unknown')\n",
    "            context += f\" - Edge: {edge[0]} ({relationship}) {edge[1]}\\n\"\n",
    "\n",
    "    inputs = tokenizer(context, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=200, \n",
    "        num_return_sequences=1, \n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Save and Load Knowledge Graph\n",
    "def save_graph(graph, filepath=\"knowledge_graph.pkl\"):\n",
    "    \"\"\"Save the knowledge graph to a file.\"\"\"\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(graph, f)\n",
    "\n",
    "def load_graph(filepath=\"knowledge_graph.pkl\"):\n",
    "    \"\"\"Load the knowledge graph from a file.\"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Main Processing Function\n",
    "def main():\n",
    "    \"\"\"Main processing loop.\"\"\"\n",
    "    save_path = \"knowledge_graph.pkl\"\n",
    "    csv_path = \"151_ideas_updated.csv\"\n",
    "\n",
    "    # Load or create the knowledge graph\n",
    "    try:\n",
    "        graph = load_graph(save_path)\n",
    "        print(\"Knowledge graph loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        graph = create_knowledge_graph_from_csv(csv_path)\n",
    "        save_graph(graph, save_path)\n",
    "        print(\"Knowledge graph created and saved.\")\n",
    "\n",
    "    # Initialize the model\n",
    "    tokenizer, model = initialize_model()\n",
    "\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"How can mindfulness improve well-being and inner beauty?\",\n",
    "        \"What is the relationship between pragmatism and philosophy?\",\n",
    "        \"Explain the connection between meditation and personal growth.\",\n",
    "        \"How does Nietzsche's view on intention relate to modern life?\",\n",
    "        \"What role does beauty play in rational decision-making?\"\n",
    "    ]\n",
    "\n",
    "    # Generate responses for each query\n",
    "    for query in queries:\n",
    "        print(f\"Query: {query}\")\n",
    "        try:\n",
    "            response = generate_with_graph_knowledge(query, model, tokenizer, graph)\n",
    "        except Exception as e:\n",
    "            response = f\"Error generating response: {e}\"\n",
    "        print(f\"Response:\\n{response}\\n\")\n",
    "\n",
    "# Example Execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nunu24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
